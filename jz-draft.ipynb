{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a variable clustering algorithm that is similar to SAS varclus\n",
    "1. PCA-based recursive decomposition\n",
    "2. stopping critiera\n",
    "3. plotting\n",
    "4. OOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "from decomposition.var_clus import VarClus, Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake data\n",
    "feature_df, label_df = make_classification(n_samples=int(1e4), n_features=50)\n",
    "feature_df = scale(feature_df)\n",
    "\n",
    "# Make sure data is zscored\n",
    "np.max(np.abs(feature_df.mean(axis=0))), np.max((feature_df.std()))\n",
    "\n",
    "feature_df = pd.DataFrame(feature_df, columns=['feature_' + str(i) for i in range(50)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some simple tests\n",
    "test_clus = Cluster(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clus.run_pca()\n",
    "type(test_clus.pca_corr), type(test_clus.pca_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clus.return_all_leaves() == test_clus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VarClus\n",
    "test_varclus = VarClus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-f94d185c177a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_varclus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\projects\\variable-clustering\\decomposition\\var_clus.py\u001b[0m in \u001b[0;36mdecompose\u001b[1;34m(self, dataframe)\u001b[0m\n\u001b[0;32m    239\u001b[0m         VarClus.__decompose(self.cluster,\n\u001b[0;32m    240\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_eigenvalue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m                             self.max_tries)\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\variable-clustering\\decomposition\\var_clus.py\u001b[0m in \u001b[0;36m__decompose\u001b[1;34m(cluster, max_eigenvalue, max_tries)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mmax_eigenvalue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVarClus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__one_step_decompose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcluster\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mchild_cluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\variable-clustering\\decomposition\\var_clus.py\u001b[0m in \u001b[0;36m__one_step_decompose\u001b[1;34m(cluster, max_tries)\u001b[0m\n\u001b[0;32m    210\u001b[0m         \u001b[1;31m# Phase 2: search algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0mchild_clusters\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             \u001b[0mVarClus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__reassign_features_pca\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_tries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_tries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mchild_clusters\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\variable-clustering\\decomposition\\var_clus.py\u001b[0m in \u001b[0;36m__reassign_features_pca\u001b[1;34m(child_clusters, max_tries)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# Loop through all features for all cluster combinations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchild_cluster\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_clusters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mother_clusters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_clusters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchild_cluster\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mchild_cluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\projects\\variable-clustering\\decomposition\\var_clus.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "test_varclus.decompose(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logic check\n",
    "cluster = Cluster(feature_df, 2)\n",
    "cluster.run_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr_table = pd.concat(cluster.pca_corr, axis=1)\n",
    "corr_max = corr_table.max(axis=1)\n",
    "cluster_membership = corr_table.apply(lambda x: x == corr_max)\n",
    "\n",
    "child_clusters = [\n",
    "    Cluster(dataframe=cluster.dataframe,\n",
    "            n_split=cluster.n_split,\n",
    "            features=[feature for (feature, condition)\n",
    "                      in cluster_membership[membership].to_dict().items()\n",
    "                      if condition],\n",
    "            parents=[cluster])\n",
    "    for membership in cluster_membership\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(child_clusters[0].features), len(child_clusters[1].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_clusters[0].dataframe.shape, child_clusters[1].dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in child_clusters:\n",
    "    if not getattr(cluster, 'pca', False):\n",
    "        cluster.run_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(child_clusters[0].pca_features[0]), child_clusters[0].pca_features[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_dataframe = pd.concat(\n",
    "    [cluster.dataframe for cluster in child_clusters],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = full_dataframe.corrwith(child_clusters[0].pca_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "corr_table = pd.concat(\n",
    "    [full_dataframe.dot(cluster.pca_features[0]) for cluster in child_clusters],\n",
    "    axis=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
